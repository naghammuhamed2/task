{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":109872,"sourceType":"datasetVersion","datasetId":57076}],"dockerImageVersionId":12783,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Data Pre-processing Stage\n\n  This notebook contains the basic data pre processing steps.","metadata":{"_uuid":"674378297bf7f78937a4f1aa466932e68466efcd"}},{"cell_type":"markdown","source":"Let's take a sample dataset for this exercise.\nThis dataset named \"data.csv\" contains whether a user purchased the product or not.\nThe users data has age,salary and the country they belonged to.","metadata":{"_uuid":"a30f7f7e2a855e2f0ef0bfc096bd4cc61a3399d9"}},{"cell_type":"code","source":"###############################################################\n#       Step 1 : Importing the libraries                      #\n###############################################################\n\n\n# NumPy is module for Python. The name is an acronym for \"Numeric Python\" or \"Numerical Python\".\n# This makes sure that the precompiled mathematical and numerical functions \n# and functionalities of Numpy guarantee great execution speed.\n\nimport numpy as np\n\n# Pandas is an open-source Python Library providing high-performance data manipulation \n# and analysis tool using its powerful data structures. \n# The name Pandas is derived from the word Panel Data – an Econometrics from Multidimensional data.\n\nimport pandas as pd\n\n\n# The OS module in Python provides a way of using operating system dependent functionality. \n# The functions that the OS module provides allows you to interface with the underlying operating system \n# that Python is running on – be that Windows, Mac or Linux.\n\nimport os","metadata":{"_uuid":"3ed37978d39bc4b4497ed16fd66a99a40df07561","execution":{"iopub.status.busy":"2024-12-23T21:25:11.869140Z","iopub.execute_input":"2024-12-23T21:25:11.869540Z","iopub.status.idle":"2024-12-23T21:25:11.874976Z","shell.execute_reply.started":"2024-12-23T21:25:11.869478Z","shell.execute_reply":"2024-12-23T21:25:11.873571Z"},"trusted":true},"outputs":[],"execution_count":48},{"cell_type":"code","source":"###############################################################\n#       Step 2 : Importing the Dataset                        #\n###############################################################\n\n#Read the 'Data.csv' and store the data in the vairable dataset.\ndataset = pd.read_csv(\"../input/Data.csv\")\nprint('Load the datasets...')\n\n\n# Print the shape of the dataset\nprint ('dataset: %s'%(str(dataset.shape)))\n","metadata":{"_uuid":"d09edc61b5ef258b23b6de01c4745613a4d00eca","execution":{"iopub.status.busy":"2024-12-23T21:25:11.880636Z","iopub.execute_input":"2024-12-23T21:25:11.880967Z","iopub.status.idle":"2024-12-23T21:25:11.893220Z","shell.execute_reply.started":"2024-12-23T21:25:11.880898Z","shell.execute_reply":"2024-12-23T21:25:11.892032Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Load the datasets...\ndataset: (15, 4)\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"The dataset contains 15 rows and 4 columns","metadata":{"_uuid":"f2255fd0287097870845b0b4dbfd4e4ac04ea9f9"}},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:25:11.895594Z","iopub.execute_input":"2024-12-23T21:25:11.895986Z","iopub.status.idle":"2024-12-23T21:25:11.925495Z","shell.execute_reply.started":"2024-12-23T21:25:11.895903Z","shell.execute_reply":"2024-12-23T21:25:11.924260Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"      Country   Age   Salary Purchased\n0       India  34.0  92000.0       Yes\n1   Sri lanka  22.0  25000.0       Yes\n2       China  31.0  74000.0       Yes\n3   Sri lanka  29.0      NaN        No\n4       China  55.0  98000.0       Yes\n5       India  24.0  30000.0        No\n6   Sri lanka  28.0  40000.0        No\n7       India   NaN  60000.0        No\n8       China  51.0  89000.0       Yes\n9       India  44.0  78000.0       Yes\n10  Sri lanka  21.0  20000.0        No\n11      China  25.0  30000.0       Yes\n12      India  33.0  45000.0       Yes\n13      India  42.0  65000.0       Yes\n14  Sri lanka  33.0  22000.0        No","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Age</th>\n      <th>Salary</th>\n      <th>Purchased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>India</td>\n      <td>34.0</td>\n      <td>92000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sri lanka</td>\n      <td>22.0</td>\n      <td>25000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>China</td>\n      <td>31.0</td>\n      <td>74000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sri lanka</td>\n      <td>29.0</td>\n      <td>NaN</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>China</td>\n      <td>55.0</td>\n      <td>98000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>India</td>\n      <td>24.0</td>\n      <td>30000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sri lanka</td>\n      <td>28.0</td>\n      <td>40000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>India</td>\n      <td>NaN</td>\n      <td>60000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>China</td>\n      <td>51.0</td>\n      <td>89000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>India</td>\n      <td>44.0</td>\n      <td>78000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Sri lanka</td>\n      <td>21.0</td>\n      <td>20000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>China</td>\n      <td>25.0</td>\n      <td>30000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>India</td>\n      <td>33.0</td>\n      <td>45000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>India</td>\n      <td>42.0</td>\n      <td>65000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Sri lanka</td>\n      <td>33.0</td>\n      <td>22000.0</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"# print the dataset\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","metadata":{"_uuid":"2764bded9c4328f4ca9902a333d882b12d09223e","execution":{"iopub.status.busy":"2024-12-23T21:25:11.928164Z","iopub.execute_input":"2024-12-23T21:25:11.928522Z","iopub.status.idle":"2024-12-23T21:25:11.941648Z","shell.execute_reply.started":"2024-12-23T21:25:11.928456Z","shell.execute_reply":"2024-12-23T21:25:11.940250Z"},"trusted":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Separate the dependent and independent variables\n\n# Independent variable\n# iloc[rows,columns]\n# Take all rows\n# Take last but one column from the dataset (:-1)\n\n\n# Dependent variable\n# iloc[rows,columns]\n# Take all rows\n# Take last column from the dataset (:-1)\n","metadata":{"_uuid":"0b51a61e0f0b243b1b3c5650a30dcf02d6f943a5","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:25:11.944667Z","iopub.execute_input":"2024-12-23T21:25:11.945076Z","iopub.status.idle":"2024-12-23T21:25:11.956133Z","shell.execute_reply.started":"2024-12-23T21:25:11.945001Z","shell.execute_reply":"2024-12-23T21:25:11.954986Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# Print the X and Y\nprint(X)\nprint(y)","metadata":{"_uuid":"5351fbd6905b93aad9c455ee99cb0814e55cfc58","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:25:11.957255Z","iopub.execute_input":"2024-12-23T21:25:11.957546Z","iopub.status.idle":"2024-12-23T21:25:11.972250Z","shell.execute_reply.started":"2024-12-23T21:25:11.957495Z","shell.execute_reply":"2024-12-23T21:25:11.971017Z"}},"outputs":[{"name":"stdout","text":"[['India' 34.0 92000.0]\n ['Sri lanka' 22.0 25000.0]\n ['China' 31.0 74000.0]\n ['Sri lanka' 29.0 nan]\n ['China' 55.0 98000.0]\n ['India' 24.0 30000.0]\n ['Sri lanka' 28.0 40000.0]\n ['India' nan 60000.0]\n ['China' 51.0 89000.0]\n ['India' 44.0 78000.0]\n ['Sri lanka' 21.0 20000.0]\n ['China' 25.0 30000.0]\n ['India' 33.0 45000.0]\n ['India' 42.0 65000.0]\n ['Sri lanka' 33.0 22000.0]]\n['Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'Yes'\n 'Yes' 'No']\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:25:11.973414Z","iopub.execute_input":"2024-12-23T21:25:11.973748Z","iopub.status.idle":"2024-12-23T21:25:11.989695Z","shell.execute_reply.started":"2024-12-23T21:25:11.973694Z","shell.execute_reply":"2024-12-23T21:25:11.988615Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"Country      0\nAge          1\nSalary       1\nPurchased    0\ndtype: int64"},"metadata":{}}],"execution_count":54},{"cell_type":"markdown","source":"#### 1. Handle Missing Data\n\nThere are few missing data in the Age and salary columns (NaN values).\n\n#### i. Deleting Rows:\n*      We cannot remove the rows with the missing data as it will affect the output of the  machine learning algorithm.\n*      However we can delete a particular row if it has a null value for a particular feature and a particular column if it has more than 70-75% of missing values.\n      \n\n#### ii. Replacing With Mean/Median/Mode:\n*      This strategy can be applied on a feature which has numeric data like the age of a person.\n*      We can calculate the mean, median or mode of the feature and replace it with the missing values.    \n*     The loss of the data can be negated by this method which yields better results compared to removal of rows and  \n*       columns.\n*      Replacing with the above three approximations are a statistical approach of handling the missing values. \n*     This method is also called as leaking the data while training. \n*     Another way is to approximate it with the deviation of neighbouring values. \n*     This works better if the data is linear.\n","metadata":{"_uuid":"dffee0eb70165f04561442a9f05bf2fd0c0d205f"}},{"cell_type":"markdown","source":"* # <font color='lime'>Solution 1 : Dropna</font>","metadata":{}},{"cell_type":"code","source":"df1 = dataset.copy()\ndf1.dropna(inplace=True)\n\nprint(\"Before:\",df1.shape)\n\n# drop rows with missing values\ndataset.dropna(inplace=True)\n\n# summarize the shape of the data with missing rows removed\nprint(\"After:\",dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:30:24.297071Z","iopub.execute_input":"2024-12-23T21:30:24.297497Z","iopub.status.idle":"2024-12-23T21:30:24.319155Z","shell.execute_reply.started":"2024-12-23T21:30:24.297422Z","shell.execute_reply":"2024-12-23T21:30:24.317780Z"}},"outputs":[{"name":"stdout","text":"Before: (13, 4)\nAfter:       Country   Age   Salary Purchased\n0       India  34.0  92000.0       Yes\n1   Sri lanka  22.0  25000.0       Yes\n2       China  31.0  74000.0       Yes\n4       China  55.0  98000.0       Yes\n5       India  24.0  30000.0        No\n6   Sri lanka  28.0  40000.0        No\n8       China  51.0  89000.0       Yes\n9       India  44.0  78000.0       Yes\n10  Sri lanka  21.0  20000.0        No\n11      China  25.0  30000.0       Yes\n12      India  33.0  45000.0       Yes\n13      India  42.0  65000.0       Yes\n14  Sri lanka  33.0  22000.0        No\n","output_type":"stream"}],"execution_count":63},{"cell_type":"markdown","source":"# <font color='chartreuse'>Solution 2 : Fillna</font>","metadata":{}},{"cell_type":"code","source":"df2 = dataset.copy()\ndf2.dropna(inplace=True)\n\nprint(\"Before:\",df1.shape)\n\n# drop rows with missing values\ndataset.fillna(df2.mean(),inplace=True)\n\n# summarize the shape of the data with missing rows removed\nprint(\"After:\",df2.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:25:12.010700Z","iopub.execute_input":"2024-12-23T21:25:12.011019Z","iopub.status.idle":"2024-12-23T21:25:12.028379Z","shell.execute_reply.started":"2024-12-23T21:25:12.010966Z","shell.execute_reply":"2024-12-23T21:25:12.027055Z"}},"outputs":[{"name":"stdout","text":"Before: (13, 4)\nAfter: (13, 4)\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"# <font color='darkgreen'>Solution 3 : Scikit-Learn</font>","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 2. Encode the Categorical data\n\nCategorical data are variables that contain label values rather than numeric values.\nSome algorithms can work with categorical data directly.\n\nFor example, a decision tree can be learned directly from categorical data with no data transform required (this depends on the specific implementation).\n\nMany machine learning algorithms cannot operate on label data directly. They require all input variables and output variables to be numeric.\n\nThis means that categorical data must be converted to a numerical form.","metadata":{"_uuid":"0504a7e75bde4ac7779062a37f144d9b9a096a17"}},{"cell_type":"markdown","source":"In our dataset there are 2 columns with categorical data.\n\nThe First column which contains the country and the last column purchased.","metadata":{"_uuid":"a8261920df0d266e0551cdae8264a07c96cdd7f8"}},{"cell_type":"markdown","source":"#### i.  Label Encoder: \n\n    * It is used to transform non-numerical labels to numerical labels (or nominal categorical variables).\n    * Numerical labels are always between 0 and n_classes-1.     \n\n#### ii. OneHotEncoder:\n    * Encode categorical integer features using a one-hot aka one-of-K scheme.\n    * The input to this transformer should be a matrix of integers, denoting the values taken on by categorical (discrete) \n      features.\n    * The output will be a sparse matrix where each column corresponds to one possible value of one feature.\n    * It is assumed that input features take on values in the range [0, n_values]\n    * This encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs\n      with the standard kernels.        ","metadata":{"_uuid":"28a61d344d1556bdac352ac69e2ed0eb0e9a0cbc"}},{"cell_type":"markdown","source":" # <font color='darkorchid'>Solution 1 : Label Encoder</font>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabel_encoder_country = LabelEncoder()\ndataset['Country_Label'] = label_encoder_country.fit_transform(dataset['Country'])\n\ndataset['Country_Label'] = label_encoder_country.fit_transform(dataset['Country'])\nprint(\"\\nAfter Label Encoding for Country:\")\nprint(dataset[['Country', 'Country_Label']].head())","metadata":{"_uuid":"ad860887b31ba69dfe706ccd320b9cebe4fe931b","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:39:17.662495Z","iopub.execute_input":"2024-12-23T21:39:17.662894Z","iopub.status.idle":"2024-12-23T21:39:17.678466Z","shell.execute_reply.started":"2024-12-23T21:39:17.662827Z","shell.execute_reply":"2024-12-23T21:39:17.677137Z"}},"outputs":[{"name":"stdout","text":"\nAfter Label Encoding for Country:\n     Country  Country_Label\n0      India              1\n1  Sri lanka              2\n2      China              0\n4      China              0\n5      India              1\n","output_type":"stream"}],"execution_count":66},{"cell_type":"markdown","source":"Now the categorical data of the country value is changed to numerical value.\n\n| Country | Value |\n|:--------|:------|\n| China   |   0   |  \n| India   |   1   |   \n| Srilanka|   2   |   \n","metadata":{"_uuid":"5f745a4a68c5e1d90dc1537940af301e69d9c164"}},{"cell_type":"markdown","source":"#### Dummy Encoding\n\n    * The above encoding will result in a problem.\n    * The label encoding transforms the data as shown in the table above.\n    * The Machine learning algorithm will assume that China>India>Sri Lanka.\n    * But this is not the case. We just converted the categorical value and assigned it to a numeric value.\n    * Hence there is a need to apply Dummy encoding to the above dataset.\n\n| Country | China | India | Sri Lanka |\n|:--------|:------|:------|:----------|\n| China   |   1   |  0    |    0      |   \n| India   |   0   |  1    |    0      |   \n| Srilanka|   0   |  0    |    1      |   \n| India   |   0   |  1    |    0      |  \n| Srilanka|   0   |  0    |    1      |  \n| China   |   1   |  0    |    0      |  \n  \n\n","metadata":{"_uuid":"9c4a6e53a3a028c11f1d9a91b9f45fbf8c64c996"}},{"cell_type":"markdown","source":"# <font color='darkorchid'>Solution 2 : ColumnTransformer</font>","metadata":{}},{"cell_type":"code","source":"# Applying the OneHotEncoder to the first column[0]\n","metadata":{"_uuid":"2594e6f27a4b8a3fda17c7def917c1884546bae1","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:25:12.040546Z","iopub.execute_input":"2024-12-23T21:25:12.040799Z","iopub.status.idle":"2024-12-23T21:25:12.052824Z","shell.execute_reply.started":"2024-12-23T21:25:12.040755Z","shell.execute_reply":"2024-12-23T21:25:12.051437Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <font color='magenta'>Solution 3 : LabelEncoder for labels</font>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n#  One-Hot Encoding for 'Country'\none_hot_encoder = OneHotEncoder(sparse=False)  # Use sparse=False to get a dense array\ncountry_encoded = one_hot_encoder.fit_transform(dataset[['Country']])\ncountry_encoded_df = pd.DataFrame(country_encoded, columns=one_hot_encoder.get_feature_names_out(['Country']))\n","metadata":{"_uuid":"614c26108b7dcd141f65bf14b67e178aee962f19","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:41:30.638380Z","iopub.execute_input":"2024-12-23T21:41:30.638802Z","iopub.status.idle":"2024-12-23T21:41:30.668615Z","shell.execute_reply.started":"2024-12-23T21:41:30.638740Z","shell.execute_reply":"2024-12-23T21:41:30.666852Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-dc69291bca6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#  One-Hot Encoding for 'Country'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mone_hot_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use sparse=False to get a dense array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcountry_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcountry_encoded_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \"\"\"\n\u001b[1;32m   2018\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 2019\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1807\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m     \"\"\"\n\u001b[0;32m-> 1809\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Sri lanka'"],"ename":"ValueError","evalue":"could not convert string to float: 'Sri lanka'","output_type":"error"}],"execution_count":68},{"cell_type":"markdown","source":"# <font color='aqua'>6- Splitting the dataset</font>\nSplitting the dataset is the next step in data preprocessing in machine learning. Every dataset for Machine Learning model must be split into two separate sets – training set and test set. ","metadata":{}},{"cell_type":"code","source":"","metadata":{"_uuid":"19b3d19ab1e4b1c1ff425d55b0eb79317bf7ab86","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <font color='lightskyblue'>7- Feature scaling</font>\nFeature scaling marks the end of the data preprocessing in Machine Learning. It is a method to standardize the independent variables of a dataset within a specific range. In other words, feature scaling limits the range of variables so that you can compare them on common grounds.\n\nAnother reason why feature scaling is applied is that few algorithms like gradient descent converge much faster with feature scaling than without it.","metadata":{}},{"cell_type":"markdown","source":"# <font color='red'>MinMax Scaler</font>\nMinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range. It scales the values to a specific value range without changing the shape of the original distribution.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <font color='red'>Standard Scaler</font>\nStandardScaler follows Standard Normal Distribution (SND). Therefore, it makes mean = 0 and scales the data to unit variance.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now the all the data are in same scale. We can now apply different Machine learning model to the dataset.","metadata":{"_uuid":"d884daf43f80af5c65844fbc763ea18c738890ec"}}]}